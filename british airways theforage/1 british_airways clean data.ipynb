{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BRITISH AIRWAYS ANALYSIS\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "pd.options.display.float_format = '{:.5f}'.format \n",
    "np.set_printoptions(suppress=True, precision=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 1\n",
      "   ---> 100 +101 + 100 + 100 total\n",
      "Scraping page 2\n",
      "   ---> 200 +202 + 200 + 200 total\n",
      "Scraping page 3\n",
      "   ---> 300 +303 + 300 + 300 total\n",
      "Scraping page 4\n",
      "   ---> 400 +404 + 400 + 400 total\n",
      "Scraping page 5\n",
      "   ---> 500 +505 + 500 + 500 total\n",
      "Scraping page 6\n",
      "   ---> 600 +606 + 600 + 600 total\n",
      "Scraping page 7\n",
      "   ---> 700 +707 + 700 + 700 total\n",
      "Scraping page 8\n",
      "   ---> 800 +808 + 800 + 800 total\n",
      "Scraping page 9\n",
      "   ---> 900 +909 + 900 + 900 total\n",
      "Scraping page 10\n",
      "   ---> 1000 +1010 + 1000 + 1000 total\n",
      "Scraping page 11\n",
      "   ---> 1100 +1111 + 1100 + 1100 total\n",
      "Scraping page 12\n",
      "   ---> 1200 +1212 + 1200 + 1200 total\n",
      "Scraping page 13\n",
      "   ---> 1300 +1313 + 1300 + 1300 total\n",
      "Scraping page 14\n",
      "   ---> 1400 +1414 + 1400 + 1400 total\n",
      "Scraping page 15\n",
      "   ---> 1500 +1515 + 1500 + 1500 total\n",
      "Scraping page 16\n",
      "   ---> 1600 +1616 + 1600 + 1600 total\n",
      "Scraping page 17\n",
      "   ---> 1700 +1717 + 1700 + 1700 total\n",
      "Scraping page 18\n",
      "   ---> 1800 +1818 + 1800 + 1800 total\n",
      "Scraping page 19\n",
      "   ---> 1900 +1919 + 1900 + 1900 total\n",
      "Scraping page 20\n",
      "   ---> 2000 +2020 + 2000 + 2000 total\n"
     ]
    }
   ],
   "source": [
    "base_url = \"https://www.airlinequality.com/airline-reviews/british-airways\"\n",
    "pages = 20\n",
    "page_size = 100\n",
    "\n",
    "reviews = []\n",
    "rating =[]\n",
    "date =[]\n",
    "country = []\n",
    "\n",
    "for i in range(1, pages+1):\n",
    "    print(f\"Scraping page {i}\")\n",
    "\n",
    "    url = f\"{base_url}/page/{i}/?sortby=post_date%3ADesc&pagesize={page_size}\"\n",
    "\n",
    "    # Collect HTML data f\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # Parse content\n",
    "    content1 = response.content\n",
    "    contents = BeautifulSoup(content1, 'html.parser')\n",
    "    for item in contents.find_all(\"div\", {\"class\": \"text_content\"}):\n",
    "        reviews.append(item.get_text())\n",
    "        #(try:\n",
    "        #   rating.append(item.span.text)\n",
    "        #except:\n",
    "            #print(f'Error on page {i}')\n",
    "            #rating.append(\"None\")\n",
    "    \n",
    "    for item in contents.find_all('div', class_ = 'rating-10'):\n",
    "            rating.append(item.span.text)\n",
    "\n",
    "    for item in contents.find_all('time'):\n",
    "        date.append(item.text)\n",
    "    \n",
    "    for item in contents.find_all('h3'):\n",
    "        country.append(item.span.next_sibling.text.strip(\" ()\"))\n",
    "\n",
    "    print(f\"   ---> {len(reviews)} +{len(rating)} + {len(date)} + {len(country)} total\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2020, 2000, 2000, 2000)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rating diff by on top overall +1 each page\n",
    "\n",
    "len(rating), len(reviews), len(date), len(country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rating removing\n",
    "new_rating = [] \n",
    "for i in range(len(rating)-1):\n",
    "    i+=1\n",
    "    if rating[i] == '\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t5':\n",
    "        continue\n",
    "    else:\n",
    "        new_rating.append(rating[i])\n",
    "len(new_rating)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>ratings</th>\n",
       "      <th>date</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Not Verified |  We were flying World Traveller...</td>\n",
       "      <td>2</td>\n",
       "      <td>14th March 2023</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Not Verified |  This was literally one of the ...</td>\n",
       "      <td>1</td>\n",
       "      <td>13th March 2023</td>\n",
       "      <td>Ireland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>✅ Trip Verified |  The usual shambolic unfoldi...</td>\n",
       "      <td>1</td>\n",
       "      <td>12th March 2023</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Not Verified |  Lost my case and took 6 weeks ...</td>\n",
       "      <td>2</td>\n",
       "      <td>12th March 2023</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>✅ Trip Verified |  The incoming and outgoing f...</td>\n",
       "      <td>1</td>\n",
       "      <td>10th March 2023</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             reviews ratings             date  \\\n",
       "0  Not Verified |  We were flying World Traveller...       2  14th March 2023   \n",
       "1  Not Verified |  This was literally one of the ...       1  13th March 2023   \n",
       "2  ✅ Trip Verified |  The usual shambolic unfoldi...       1  12th March 2023   \n",
       "3  Not Verified |  Lost my case and took 6 weeks ...       2  12th March 2023   \n",
       "4  ✅ Trip Verified |  The incoming and outgoing f...       1  10th March 2023   \n",
       "\n",
       "          country  \n",
       "0  United Kingdom  \n",
       "1         Ireland  \n",
       "2  United Kingdom  \n",
       "3  United Kingdom  \n",
       "4  United Kingdom  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Tạo bảng cho dataframe mới\n",
    "df = pd.DataFrame({\"reviews\":reviews,\"ratings\": new_rating, \"date\":date, \"country\": country})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv(\"E:/learn st new/BA_reviews2.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean dữ liệu\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review2 = []\n",
    "x = '|'\n",
    "for i in range(0, 2000):\n",
    "    if x in reviews[i]:\n",
    "        review2.append(reviews[i])\n",
    "    else:\n",
    "        review2.append(str(x +' '+ reviews[i]))\n",
    "len(review2)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>ratings</th>\n",
       "      <th>date</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Not Verified |  We were flying World Traveller...</td>\n",
       "      <td>2</td>\n",
       "      <td>14th March 2023</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Not Verified |  This was literally one of the ...</td>\n",
       "      <td>1</td>\n",
       "      <td>13th March 2023</td>\n",
       "      <td>Ireland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>✅ Trip Verified |  The usual shambolic unfoldi...</td>\n",
       "      <td>1</td>\n",
       "      <td>12th March 2023</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Not Verified |  Lost my case and took 6 weeks ...</td>\n",
       "      <td>2</td>\n",
       "      <td>12th March 2023</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>✅ Trip Verified |  The incoming and outgoing f...</td>\n",
       "      <td>1</td>\n",
       "      <td>10th March 2023</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             reviews ratings             date  \\\n",
       "0  Not Verified |  We were flying World Traveller...       2  14th March 2023   \n",
       "1  Not Verified |  This was literally one of the ...       1  13th March 2023   \n",
       "2  ✅ Trip Verified |  The usual shambolic unfoldi...       1  12th March 2023   \n",
       "3  Not Verified |  Lost my case and took 6 weeks ...       2  12th March 2023   \n",
       "4  ✅ Trip Verified |  The incoming and outgoing f...       1  10th March 2023   \n",
       "\n",
       "          country  \n",
       "0  United Kingdom  \n",
       "1         Ireland  \n",
       "2  United Kingdom  \n",
       "3  United Kingdom  \n",
       "4  United Kingdom  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.DataFrame({\"reviews\":review2,\"ratings\": new_rating, \"date\":date, \"country\": country})\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_clean = df2.reviews.str.split('|', expand=True)[1]\n",
    "df2['clean_review'] = review_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['verified'] = df2.reviews.str.contains(\"Trip Verified\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean(text):\n",
    "    text = re.sub('[^A-Za-z]+', ' ', str(text))\n",
    "    return text\n",
    "\n",
    "df2['Cleaned Reviews'] = df2['clean_review'].apply(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>ratings</th>\n",
       "      <th>date</th>\n",
       "      <th>country</th>\n",
       "      <th>clean_review</th>\n",
       "      <th>verified</th>\n",
       "      <th>Cleaned Reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Not Verified |  We were flying World Traveller...</td>\n",
       "      <td>2</td>\n",
       "      <td>2023-03-14</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>We were flying World Traveller Plus their Pr...</td>\n",
       "      <td>False</td>\n",
       "      <td>We were flying World Traveller Plus their Pre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Not Verified |  This was literally one of the ...</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-03-13</td>\n",
       "      <td>Ireland</td>\n",
       "      <td>This was literally one of the worst experien...</td>\n",
       "      <td>False</td>\n",
       "      <td>This was literally one of the worst experienc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>✅ Trip Verified |  The usual shambolic unfoldi...</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-03-12</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>The usual shambolic unfolding that BA has no...</td>\n",
       "      <td>True</td>\n",
       "      <td>The usual shambolic unfolding that BA has now...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Not Verified |  Lost my case and took 6 weeks ...</td>\n",
       "      <td>2</td>\n",
       "      <td>2023-03-12</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Lost my case and took 6 weeks to locate it a...</td>\n",
       "      <td>False</td>\n",
       "      <td>Lost my case and took weeks to locate it and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>✅ Trip Verified |  The incoming and outgoing f...</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-03-10</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>The incoming and outgoing flight was delayed...</td>\n",
       "      <td>True</td>\n",
       "      <td>The incoming and outgoing flight was delayed ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             reviews ratings       date  \\\n",
       "0  Not Verified |  We were flying World Traveller...       2 2023-03-14   \n",
       "1  Not Verified |  This was literally one of the ...       1 2023-03-13   \n",
       "2  ✅ Trip Verified |  The usual shambolic unfoldi...       1 2023-03-12   \n",
       "3  Not Verified |  Lost my case and took 6 weeks ...       2 2023-03-12   \n",
       "4  ✅ Trip Verified |  The incoming and outgoing f...       1 2023-03-10   \n",
       "\n",
       "          country                                       clean_review  \\\n",
       "0  United Kingdom    We were flying World Traveller Plus their Pr...   \n",
       "1         Ireland    This was literally one of the worst experien...   \n",
       "2  United Kingdom    The usual shambolic unfolding that BA has no...   \n",
       "3  United Kingdom    Lost my case and took 6 weeks to locate it a...   \n",
       "4  United Kingdom    The incoming and outgoing flight was delayed...   \n",
       "\n",
       "   verified                                    Cleaned Reviews  \n",
       "0     False   We were flying World Traveller Plus their Pre...  \n",
       "1     False   This was literally one of the worst experienc...  \n",
       "2      True   The usual shambolic unfolding that BA has now...  \n",
       "3     False   Lost my case and took weeks to locate it and ...  \n",
       "4      True   The incoming and outgoing flight was delayed ...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.date= pd.to_datetime(df2.date)\n",
    "df2.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize Dữ liệu và Enrichment – POS tagging\n",
    "---\n",
    "Tokenization nhằm đưa câu phức thành những nhóm những từ đơn giản\n",
    "\n",
    "Pos Tag == đưa dữ liệu vào nhóm (tên + tag) mà vẫn giữ được context của từ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\OS\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\OS\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\OS\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##This punkt tokenizer divides a text into a list of sentences by using an unsupervised algorithm to build a model for abbreviation words, collocations, and words that start sentences\n",
    "nltk.download('punkt')\n",
    "\n",
    "#The nltk.corpus package defines a collection of corpus reader classes, which can be used to access the contents of a diverse set of corpora.\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>ratings</th>\n",
       "      <th>date</th>\n",
       "      <th>country</th>\n",
       "      <th>clean_review</th>\n",
       "      <th>verified</th>\n",
       "      <th>Cleaned Reviews</th>\n",
       "      <th>POS tagged</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Not Verified |  We were flying World Traveller...</td>\n",
       "      <td>2</td>\n",
       "      <td>2023-03-14</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>We were flying World Traveller Plus their Pr...</td>\n",
       "      <td>False</td>\n",
       "      <td>We were flying World Traveller Plus their Pre...</td>\n",
       "      <td>[(flying, v), (World, n), (Traveller, n), (Plu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Not Verified |  This was literally one of the ...</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-03-13</td>\n",
       "      <td>Ireland</td>\n",
       "      <td>This was literally one of the worst experien...</td>\n",
       "      <td>False</td>\n",
       "      <td>This was literally one of the worst experienc...</td>\n",
       "      <td>[(literally, r), (one, None), (worst, a), (exp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>✅ Trip Verified |  The usual shambolic unfoldi...</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-03-12</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>The usual shambolic unfolding that BA has no...</td>\n",
       "      <td>True</td>\n",
       "      <td>The usual shambolic unfolding that BA has now...</td>\n",
       "      <td>[(usual, a), (shambolic, n), (unfolding, v), (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Not Verified |  Lost my case and took 6 weeks ...</td>\n",
       "      <td>2</td>\n",
       "      <td>2023-03-12</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Lost my case and took 6 weeks to locate it a...</td>\n",
       "      <td>False</td>\n",
       "      <td>Lost my case and took weeks to locate it and ...</td>\n",
       "      <td>[(Lost, v), (case, n), (took, v), (weeks, n), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>✅ Trip Verified |  The incoming and outgoing f...</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-03-10</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>The incoming and outgoing flight was delayed...</td>\n",
       "      <td>True</td>\n",
       "      <td>The incoming and outgoing flight was delayed ...</td>\n",
       "      <td>[(incoming, n), (outgoing, v), (flight, n), (d...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             reviews ratings       date  \\\n",
       "0  Not Verified |  We were flying World Traveller...       2 2023-03-14   \n",
       "1  Not Verified |  This was literally one of the ...       1 2023-03-13   \n",
       "2  ✅ Trip Verified |  The usual shambolic unfoldi...       1 2023-03-12   \n",
       "3  Not Verified |  Lost my case and took 6 weeks ...       2 2023-03-12   \n",
       "4  ✅ Trip Verified |  The incoming and outgoing f...       1 2023-03-10   \n",
       "\n",
       "          country                                       clean_review  \\\n",
       "0  United Kingdom    We were flying World Traveller Plus their Pr...   \n",
       "1         Ireland    This was literally one of the worst experien...   \n",
       "2  United Kingdom    The usual shambolic unfolding that BA has no...   \n",
       "3  United Kingdom    Lost my case and took 6 weeks to locate it a...   \n",
       "4  United Kingdom    The incoming and outgoing flight was delayed...   \n",
       "\n",
       "   verified                                    Cleaned Reviews  \\\n",
       "0     False   We were flying World Traveller Plus their Pre...   \n",
       "1     False   This was literally one of the worst experienc...   \n",
       "2      True   The usual shambolic unfolding that BA has now...   \n",
       "3     False   Lost my case and took weeks to locate it and ...   \n",
       "4      True   The incoming and outgoing flight was delayed ...   \n",
       "\n",
       "                                          POS tagged  \n",
       "0  [(flying, v), (World, n), (Traveller, n), (Plu...  \n",
       "1  [(literally, r), (one, None), (worst, a), (exp...  \n",
       "2  [(usual, a), (shambolic, n), (unfolding, v), (...  \n",
       "3  [(Lost, v), (case, n), (took, v), (weeks, n), ...  \n",
       "4  [(incoming, n), (outgoing, v), (flight, n), (d...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# POS tagger dictionary\n",
    "pos_dict = {'J':wordnet.ADJ, 'V':wordnet.VERB, 'N':wordnet.NOUN, 'R':wordnet.ADV}\n",
    "def token_stop_pos(text):\n",
    "    tags = pos_tag(word_tokenize(text))\n",
    "    #print(tags)\n",
    "    newlist = []\n",
    "    for word, tag in tags:\n",
    "        if word.lower() not in set(stopwords.words('english')):\n",
    "          newlist.append(tuple([word, pos_dict.get(tag[0])]))\n",
    "    return newlist \n",
    "\n",
    "df2['POS tagged'] = df2['Cleaned Reviews'].apply(token_stop_pos)\n",
    "df2.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bỏ Stopwords + Thêm stem words\n",
    "--- \n",
    "* Stopwords là những từ đơn giản nên rất khó để đưa ra thông tin hữu ích. Vì vậy nên cần xử lý để chuyển các stopwords thành chuỗi có ý nghĩa bằng việc loại bỏ các từ không cần thiết bằng Lemma\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>ratings</th>\n",
       "      <th>date</th>\n",
       "      <th>country</th>\n",
       "      <th>clean_review</th>\n",
       "      <th>verified</th>\n",
       "      <th>Cleaned Reviews</th>\n",
       "      <th>POS tagged</th>\n",
       "      <th>Lemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Not Verified |  We were flying World Traveller...</td>\n",
       "      <td>2</td>\n",
       "      <td>2023-03-14</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>We were flying World Traveller Plus their Pr...</td>\n",
       "      <td>False</td>\n",
       "      <td>We were flying World Traveller Plus their Pre...</td>\n",
       "      <td>[(flying, v), (World, n), (Traveller, n), (Plu...</td>\n",
       "      <td>fly World Traveller Plus Premium service Pre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Not Verified |  This was literally one of the ...</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-03-13</td>\n",
       "      <td>Ireland</td>\n",
       "      <td>This was literally one of the worst experien...</td>\n",
       "      <td>False</td>\n",
       "      <td>This was literally one of the worst experienc...</td>\n",
       "      <td>[(literally, r), (one, None), (worst, a), (exp...</td>\n",
       "      <td>literally one bad experience airport since b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>✅ Trip Verified |  The usual shambolic unfoldi...</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-03-12</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>The usual shambolic unfolding that BA has no...</td>\n",
       "      <td>True</td>\n",
       "      <td>The usual shambolic unfolding that BA has now...</td>\n",
       "      <td>[(usual, a), (shambolic, n), (unfolding, v), (...</td>\n",
       "      <td>usual shambolic unfold BA unfortunately come...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Not Verified |  Lost my case and took 6 weeks ...</td>\n",
       "      <td>2</td>\n",
       "      <td>2023-03-12</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Lost my case and took 6 weeks to locate it a...</td>\n",
       "      <td>False</td>\n",
       "      <td>Lost my case and took weeks to locate it and ...</td>\n",
       "      <td>[(Lost, v), (case, n), (took, v), (weeks, n), ...</td>\n",
       "      <td>Lost case take week locate still reply week ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>✅ Trip Verified |  The incoming and outgoing f...</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-03-10</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>The incoming and outgoing flight was delayed...</td>\n",
       "      <td>True</td>\n",
       "      <td>The incoming and outgoing flight was delayed ...</td>\n",
       "      <td>[(incoming, n), (outgoing, v), (flight, n), (d...</td>\n",
       "      <td>incoming outgo flight delay French Air Traff...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             reviews ratings       date  \\\n",
       "0  Not Verified |  We were flying World Traveller...       2 2023-03-14   \n",
       "1  Not Verified |  This was literally one of the ...       1 2023-03-13   \n",
       "2  ✅ Trip Verified |  The usual shambolic unfoldi...       1 2023-03-12   \n",
       "3  Not Verified |  Lost my case and took 6 weeks ...       2 2023-03-12   \n",
       "4  ✅ Trip Verified |  The incoming and outgoing f...       1 2023-03-10   \n",
       "\n",
       "          country                                       clean_review  \\\n",
       "0  United Kingdom    We were flying World Traveller Plus their Pr...   \n",
       "1         Ireland    This was literally one of the worst experien...   \n",
       "2  United Kingdom    The usual shambolic unfolding that BA has no...   \n",
       "3  United Kingdom    Lost my case and took 6 weeks to locate it a...   \n",
       "4  United Kingdom    The incoming and outgoing flight was delayed...   \n",
       "\n",
       "   verified                                    Cleaned Reviews  \\\n",
       "0     False   We were flying World Traveller Plus their Pre...   \n",
       "1     False   This was literally one of the worst experienc...   \n",
       "2      True   The usual shambolic unfolding that BA has now...   \n",
       "3     False   Lost my case and took weeks to locate it and ...   \n",
       "4      True   The incoming and outgoing flight was delayed ...   \n",
       "\n",
       "                                          POS tagged  \\\n",
       "0  [(flying, v), (World, n), (Traveller, n), (Plu...   \n",
       "1  [(literally, r), (one, None), (worst, a), (exp...   \n",
       "2  [(usual, a), (shambolic, n), (unfolding, v), (...   \n",
       "3  [(Lost, v), (case, n), (took, v), (weeks, n), ...   \n",
       "4  [(incoming, n), (outgoing, v), (flight, n), (d...   \n",
       "\n",
       "                                               Lemma  \n",
       "0    fly World Traveller Plus Premium service Pre...  \n",
       "1    literally one bad experience airport since b...  \n",
       "2    usual shambolic unfold BA unfortunately come...  \n",
       "3    Lost case take week locate still reply week ...  \n",
       "4    incoming outgo flight delay French Air Traff...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Obtaining the stem words – Lemmatization\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "def lemmatize(pos_data):\n",
    "    lemma_rew = \" \"\n",
    "    for word, pos in pos_data:\n",
    "     if not pos:\n",
    "        lemma = word\n",
    "        lemma_rew = lemma_rew + \" \" + lemma\n",
    "     else:\n",
    "        lemma = wordnet_lemmatizer.lemmatize(word, pos=pos)\n",
    "        lemma_rew = lemma_rew + \" \" + lemma\n",
    "    return lemma_rew\n",
    "\n",
    "df2['Lemma'] = df2['POS tagged'].apply(lemmatize)\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: vaderSentiment in d:\\python\\lib\\site-packages (3.3.2)\n",
      "Requirement already satisfied: requests in d:\\python\\lib\\site-packages (from vaderSentiment) (2.28.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in d:\\python\\lib\\site-packages (from requests->vaderSentiment) (1.26.15)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\python\\lib\\site-packages (from requests->vaderSentiment) (3.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\python\\lib\\site-packages (from requests->vaderSentiment) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\python\\lib\\site-packages (from requests->vaderSentiment) (3.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install vaderSentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>ratings</th>\n",
       "      <th>date</th>\n",
       "      <th>country</th>\n",
       "      <th>clean_review</th>\n",
       "      <th>verified</th>\n",
       "      <th>Cleaned Reviews</th>\n",
       "      <th>POS tagged</th>\n",
       "      <th>Lemma</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Analysis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Not Verified |  We were flying World Traveller...</td>\n",
       "      <td>2</td>\n",
       "      <td>2023-03-14</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>We were flying World Traveller Plus their Pr...</td>\n",
       "      <td>False</td>\n",
       "      <td>We were flying World Traveller Plus their Pre...</td>\n",
       "      <td>[(flying, v), (World, n), (Traveller, n), (Plu...</td>\n",
       "      <td>fly World Traveller Plus Premium service Pre...</td>\n",
       "      <td>-0.89570</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Not Verified |  This was literally one of the ...</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-03-13</td>\n",
       "      <td>Ireland</td>\n",
       "      <td>This was literally one of the worst experien...</td>\n",
       "      <td>False</td>\n",
       "      <td>This was literally one of the worst experienc...</td>\n",
       "      <td>[(literally, r), (one, None), (worst, a), (exp...</td>\n",
       "      <td>literally one bad experience airport since b...</td>\n",
       "      <td>-0.83160</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>✅ Trip Verified |  The usual shambolic unfoldi...</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-03-12</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>The usual shambolic unfolding that BA has no...</td>\n",
       "      <td>True</td>\n",
       "      <td>The usual shambolic unfolding that BA has now...</td>\n",
       "      <td>[(usual, a), (shambolic, n), (unfolding, v), (...</td>\n",
       "      <td>usual shambolic unfold BA unfortunately come...</td>\n",
       "      <td>-0.42150</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Not Verified |  Lost my case and took 6 weeks ...</td>\n",
       "      <td>2</td>\n",
       "      <td>2023-03-12</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Lost my case and took 6 weeks to locate it a...</td>\n",
       "      <td>False</td>\n",
       "      <td>Lost my case and took weeks to locate it and ...</td>\n",
       "      <td>[(Lost, v), (case, n), (took, v), (weeks, n), ...</td>\n",
       "      <td>Lost case take week locate still reply week ...</td>\n",
       "      <td>-0.39030</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>✅ Trip Verified |  The incoming and outgoing f...</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-03-10</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>The incoming and outgoing flight was delayed...</td>\n",
       "      <td>True</td>\n",
       "      <td>The incoming and outgoing flight was delayed ...</td>\n",
       "      <td>[(incoming, n), (outgoing, v), (flight, n), (d...</td>\n",
       "      <td>incoming outgo flight delay French Air Traff...</td>\n",
       "      <td>-0.92430</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             reviews ratings       date  \\\n",
       "0  Not Verified |  We were flying World Traveller...       2 2023-03-14   \n",
       "1  Not Verified |  This was literally one of the ...       1 2023-03-13   \n",
       "2  ✅ Trip Verified |  The usual shambolic unfoldi...       1 2023-03-12   \n",
       "3  Not Verified |  Lost my case and took 6 weeks ...       2 2023-03-12   \n",
       "4  ✅ Trip Verified |  The incoming and outgoing f...       1 2023-03-10   \n",
       "\n",
       "          country                                       clean_review  \\\n",
       "0  United Kingdom    We were flying World Traveller Plus their Pr...   \n",
       "1         Ireland    This was literally one of the worst experien...   \n",
       "2  United Kingdom    The usual shambolic unfolding that BA has no...   \n",
       "3  United Kingdom    Lost my case and took 6 weeks to locate it a...   \n",
       "4  United Kingdom    The incoming and outgoing flight was delayed...   \n",
       "\n",
       "   verified                                    Cleaned Reviews  \\\n",
       "0     False   We were flying World Traveller Plus their Pre...   \n",
       "1     False   This was literally one of the worst experienc...   \n",
       "2      True   The usual shambolic unfolding that BA has now...   \n",
       "3     False   Lost my case and took weeks to locate it and ...   \n",
       "4      True   The incoming and outgoing flight was delayed ...   \n",
       "\n",
       "                                          POS tagged  \\\n",
       "0  [(flying, v), (World, n), (Traveller, n), (Plu...   \n",
       "1  [(literally, r), (one, None), (worst, a), (exp...   \n",
       "2  [(usual, a), (shambolic, n), (unfolding, v), (...   \n",
       "3  [(Lost, v), (case, n), (took, v), (weeks, n), ...   \n",
       "4  [(incoming, n), (outgoing, v), (flight, n), (d...   \n",
       "\n",
       "                                               Lemma  Sentiment  Analysis  \n",
       "0    fly World Traveller Plus Premium service Pre...   -0.89570  Negative  \n",
       "1    literally one bad experience airport since b...   -0.83160  Negative  \n",
       "2    usual shambolic unfold BA unfortunately come...   -0.42150  Negative  \n",
       "3    Lost case take week locate still reply week ...   -0.39030  Negative  \n",
       "4    incoming outgo flight delay French Air Traff...   -0.92430  Negative  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "\n",
    "# function to calculate vader sentiment\n",
    "def vadersentimentanalysis(review):\n",
    "    vs = analyzer.polarity_scores(review)\n",
    "    return vs['compound']\n",
    "\n",
    "df2['Sentiment'] = df2['Lemma'].apply(vadersentimentanalysis)\n",
    "\n",
    "# function to analyse\n",
    "def vader_analysis(compound):\n",
    "    if compound >= 0.5:\n",
    "        return 'Positive'\n",
    "    elif compound < 0 :\n",
    "        return 'Negative'\n",
    "    else:\n",
    "        return 'Neutral'\n",
    "df2['Analysis'] = df2['Sentiment'].apply(vader_analysis)\n",
    "df2.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
